{
    "componentChunkName": "component---gatsby-theme-academic-src-templates-tags-index-jsx",
    "path": "/tags/World Model",
    "result": {"data":{"allTag":{"edges":[{"node":{"color":"magenta","name":"World Model","description":null,"path":"/tags/World Model"}},{"node":{"color":"green","name":"Video Generation","description":null,"path":"/tags/Video Generation"}},{"node":{"color":"red","name":"Long-term Consistency","description":null,"path":"/tags/Long-term Consistency"}},{"node":{"color":"magenta","name":"Diffusion","description":null,"path":"/tags/Diffusion"}},{"node":{"color":"red","name":"LLM","description":null,"path":"/tags/LLM"}},{"node":{"color":"magenta","name":"Efficiency","description":null,"path":"/tags/Efficiency"}},{"node":{"color":"volcano","name":"Adversarial Perturbations","description":null,"path":"/tags/Adversarial Perturbations"}},{"node":{"color":"volcano","name":"AI Safety","description":null,"path":"/tags/AI Safety"}},{"node":{"color":"geekblue","name":"writing","description":null,"path":"/tags/writing"}},{"node":{"color":"blue","name":"research","description":null,"path":"/tags/research"}},{"node":{"color":"volcano","name":"AI Interpretability","description":null,"path":"/tags/AI Interpretability"}},{"node":{"color":"red","name":"skills","description":null,"path":"/tags/skills"}},{"node":{"color":"red","name":"paper","description":null,"path":"/tags/paper"}},{"node":{"color":"lime","name":"ML","description":null,"path":"/tags/ML"}},{"node":{"color":"cyan","name":"gatsby","description":null,"path":"/tags/gatsby"}},{"node":{"color":"cyan","name":"blog","description":null,"path":"/tags/blog"}},{"node":{"color":"blue","name":"test1","description":null,"path":"/tags/test1"}},{"node":{"color":"blue","name":"test2","description":null,"path":"/tags/test2"}},{"node":{"color":"blue","name":"test3","description":null,"path":"/tags/test3"}},{"node":{"color":"blue","name":"influence function","description":null,"path":"/tags/influence function"}},{"node":{"color":"orange","name":"Equivariant Models","description":null,"path":"/tags/Equivariant Models"}},{"node":{"color":"orange","name":"Data Attribution","description":null,"path":"/tags/Data Attribution"}},{"node":{"color":"green","name":"Survey","description":null,"path":"/tags/Survey"}},{"node":{"color":"gold","name":"GenAI","description":null,"path":"/tags/GenAI"}},{"node":{"color":"magenta","name":"Data-centric AI","description":null,"path":"/tags/Data-centric AI"}},{"node":{"color":"gold","name":"Game Generation","description":null,"path":"/tags/Game Generation"}},{"node":{"color":"magenta","name":"Benchmark","description":null,"path":"/tags/Benchmark"}},{"node":{"color":"lime","name":"LLM Agent","description":null,"path":"/tags/LLM Agent"}},{"node":{"color":"lime","name":"Image to Video","description":null,"path":"/tags/Image to Video"}},{"node":{"color":"red","name":"3D-Reconstruction","description":null,"path":"/tags/3D-Reconstruction"}},{"node":{"color":"orange","name":"CV","description":null,"path":"/tags/CV"}},{"node":{"color":"volcano","name":"AGI(Image)","description":null,"path":"/tags/AGI(Image)"}},{"node":{"color":"gold","name":"Evaluation","description":null,"path":"/tags/Evaluation"}},{"node":{"color":"lime","name":"Model-Arch","description":null,"path":"/tags/Model-Arch"}},{"node":{"color":"orange","name":"Coq","description":null,"path":"/tags/Coq"}},{"node":{"color":"gold","name":"FormalVerification","description":null,"path":"/tags/FormalVerification"}},{"node":{"color":"green","name":"React","description":null,"path":"/tags/React"}},{"node":{"color":"green","name":"MongoDB","description":null,"path":"/tags/MongoDB"}},{"node":{"color":"green","name":"RL","description":null,"path":"/tags/RL"}},{"node":{"color":"orange","name":"DDQN","description":null,"path":"/tags/DDQN"}},{"node":{"color":"lime","name":"MCTS","description":null,"path":"/tags/MCTS"}},{"node":{"color":"cyan","name":"Vue.js","description":null,"path":"/tags/Vue.js"}},{"node":{"color":"cyan","name":"echarts","description":null,"path":"/tags/echarts"}},{"node":{"color":"cyan","name":"element-ui","description":null,"path":"/tags/element-ui"}},{"node":{"color":"volcano","name":"C++","description":null,"path":"/tags/C++"}},{"node":{"color":"gold","name":"Game Design","description":null,"path":"/tags/Game Design"}}]},"allMdx":{"edges":[{"node":{"frontmatter":{"cover":{"publicURL":"/static/7e21123f407fca3316b5629d6441314d/pan.gif"},"date":"2025-11-13","venue":"","authors":["Jiannan Xiang","Yi Gu","Zihan Liu","Zeyu Feng","Qiyue Gao","Yiyan Hu","**Benhao Huang**","Guangyi Liu","Yichi Yang","Kun Zhou","Davit Abrahamyan","Arif Ahmad","Ganesh Bannur","Junrong Chen","Kimi Chen","Mingkai Deng","Ruobing Han","Xinqi Huang","Haoqiang Kang","Zheqi Li","Enze Ma","Hector Ren","Yashowardhan Shinde","Rohan Shingre","Ramsundar Tanikella","Kaiming Tao","Dequan Yang","Xinle Yu","Cong Zeng","Binglin Zhou","Hector Liu","Zhiting Hu","Eric P. Xing"],"path":"research/2025/pan","title":"PAN: A World Model for General, Interactable, and Long-Horizon World Simulation","tags":["World Model","Video Generation","Long-term Consistency"],"excerpt":"PAN brings imagination to life — fusing language, action, and vision to simulate the world's evolution with stunning realism and consistency.","highlight":true,"links":[{"name":"technical report","url":"https://arxiv.org/abs/2511.09057"},{"name":"Blog","url":"https://panworld.ai/"}],"type":"research"}}},{"node":{"frontmatter":{"cover":{"publicURL":"/static/1ff8e96d5f97dd47e6d838f3442afae4/flowm_preview.gif"},"date":"2025-09-23","venue":"","authors":["[Hansen Lillemark*](https://hlillemark.github.io/)","**Benhao Huang***","[Fangneng Zhan](https://fnzhan.com/)","[Yilun Du](https://yilundu.github.io/)","[T. Anderson Keller](https://akandykeller.github.io/about/)"],"path":"research/2025/flowm","title":"Flow Equivariant World Models: Structured Dynamics Outside the Field of View","tags":["World Model","Equivariant Models","Long-term Consistency"],"excerpt":"On World Modeling the partially observable dynamics in the environment.","highlight":true,"links":[{"name":"paper","url":"https://openreview.net/pdf?id=WLxwYlkPHp"},{"name":"code","url":"https://github.com/AnonFloWM/Flow-Equivariant-World-Modeling"}],"type":"research"}}},{"node":{"frontmatter":{"cover":{"publicURL":"/static/122a1b0a34e05b44a20107ffbb9bb4ad/mirage.gif"},"date":"2025-07-01","venue":"","authors":["[Dynamics Lab](https://x.com/DynamicsLab_AI)"],"path":"research/2025/mirage","title":"Mirage: Generative World Engine","tags":["World Model","Game Generation"],"excerpt":"The World's First Al-Native UGC Game Engine Powered by Real-Time World Model","highlight":true,"links":[{"name":"新智元","url":"https://mp.weixin.qq.com/s/KeFkjhxkxhwGop5cNJwMOg"},{"name":"Blog","url":"https://blog.dynamicslab.ai/"}],"type":"research"}}},{"node":{"frontmatter":{"cover":{"publicURL":"/static/6ff9fe434382942e85ce0e87a3a4ed21/preview.png"},"date":"2025-06-01","venue":"ICLR 2025 Workshop World Models / ACL 2025 Findings","authors":["Qiyue Gao","Xinyu Pi","Kevin Liu","Junrong Chen","Ruolan Yang","Xinqi Huang","Xinyu Fang","Lu Sun","Gautham Kishore","Bo Ai","Stone Tao","Mengyang Liu","Jiaxi Yang","Chao-Jung Lai","Chuanyang Jin","Jiannan Xiang","**Benhao Huang**","Zeming Chen","David Danks","Hao Su","Tianming Shu","Ziqiao Ma","Lianhui Qin","Zhiting Hu"],"path":"research/2025/wm-bench","title":"Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation","tags":["World Model","Benchmark"],"excerpt":"This paper evaluates whether modern Vision-Language Models (VLMs) like GPT-4o and Gemini can act as internal world models (WMs)—systems that understand and predict the world.","highlight":null,"links":[{"name":"paper","url":"https://arxiv.org/abs/2506.21876"},{"name":"HuggingFace","url":"https://huggingface.co/datasets/maitrix-org/WM-ABench"},{"name":"website","url":"https://wm-abench.maitrix.org/"}],"type":"research"}}}]},"allFile":{"edges":[]}},"pageContext":{"fileAbsolutePath":"","tag":"World Model"}},
    "staticQueryHashes": ["1858131618","277565096","4097791827"]}