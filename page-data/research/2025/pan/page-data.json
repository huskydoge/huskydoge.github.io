{
    "componentChunkName": "component---gatsby-theme-academic-src-templates-post-post-jsx",
    "path": "/research/2025/pan",
    "result": {"data":{"mdx":{"timeToRead":1,"tableOfContents":{},"frontmatter":{"cover":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='320'%20height='180'%20viewBox='0%200%20320%20180'%20preserveAspectRatio='none'%3e%3cpath%20d='M187%202l-4%202-2%201-8%203-12%205-8%205a124%20124%200%2000-14%208c-2%200-4%202-5%203l-3%202h10l-6%202-9%202a146%20146%200%2000-36%209v6l12%201c9%201%2012%201%2015%204l15%205c10%202%2014%205%2016%2011%201%206-5%2015-13%2019l-21%205c-1-1-3-6-5-17l-4-16c-2-2-3%200-3%204l-1%204-1%202-6%2024c-1%204-3%202-5-6-3-18-5-17-8%206-1%206-4%207-5%200-2-8-4-6-6%204l-1%2010h30l-5-2-8-1-4-1%204-1c8-2%2024-3%2068-3%2037%200%2070%201%2056%202l-4%201-3%203-3%203-37%201c-66%201-70%202-75%209-2%202-3%203-5%203s-3%200-3%203l-1%204v-4c0-3%200-4-3-4-6-2-7-1-8%203l-1%204-1-4c-1-5%200-5-7-5l-5-1v8c0%209%200%208%2011%2018%209%208%2011%2012%2011%2016l3%206%203%206c-2%204%201%206%207%206h6v-56l3-2c4-3%2011-5%2011-3l-2%202c-5%202-6%203-5%2032%200%2023%200%2027%202%2027l1-27v-28l4-3%207-3c2%200%202%200-1%203l-4%204v54h107v-7c0-8%200-8%204-8s5-2%205-23c0-19%200-18-8-21-7-2-7-3%200-1s11%204%2011%205v56l5-6c4-3%205-6%205-8s1-4%204-6l4-6c0-2%202-5%2010-11%208-8%209-9%209-17%200-11-4-16-14-21-4-2-5-2-6-6-1-10-4-11-6-3%200%204-1%205-2%203l-3-11c-3-15-4-16-7-3-2%2012-2%2012-3%2011l-5-17-4-18c-1-3-3-2-3%201%200%202%200%202-1%201-1-2-1-1-1%203l-5%2022-1%207-9-2c-15-3-24-11-25-20-1-8%204-11%2017-15%205-1%2011-3%2013-5%204-2%205-2%2014-2%2014%200%2016-1%2016-6%200-6-6-13-13-14-2-1-3-2-4-6-3-7-9-16-15-21s-9-6-13-3m-8%2024c-4%201-9%203-11%206-1%201-1%201%205%201%208-1%2021-5%2018-6s-9-2-12-1m68%2029c-5%205-4%206%205%206%208%200%2010-2%205-8-3-4-5-4-10%202M49%2057c-7%205-8%206-5%207%203%202%2018%201%2019%200%203-3%200-12-4-12l-10%205m80%2049a240%20240%200%2001-24%202%201141%201141%200%200094-1c-2-2-58-2-70-1m13%2012l-15%205-5%203-1%2012v12l2-7%201-11v-3h8a1153%201153%200%200175-2c5%200%205%200%203-2-14-7-49-11-68-7'%20fill='%23d3d3d3'%20fill-rule='evenodd'/%3e%3c/svg%3e","aspectRatio":1.2019230769230769,"src":"/static/7bf9dfbe5722f2bb408dada93bac41a8/2a4de/preview.png","srcSet":"/static/7bf9dfbe5722f2bb408dada93bac41a8/e1953/preview.png 250w,\n/static/7bf9dfbe5722f2bb408dada93bac41a8/46604/preview.png 500w,\n/static/7bf9dfbe5722f2bb408dada93bac41a8/2a4de/preview.png 600w","sizes":"(max-width: 600px) 100vw, 600px"}}},"title":"PAN: Towards General World Model with Natural Language Actions and Video States","date":"","tags":["World Model","Image to Video","Diffusion"],"path":"research/2025/pan","excerpt":"A step towards a General World Model (GWM) that can simulate complex video scenarios with natural language actions.","links":[{"name":"paper (in progress)","url":null},{"name":"report-v1","url":"https://world-model.maitrix.org/assets/pandora.pdf"},{"name":"code","url":"https://github.com/maitrix-org/Pandora"}],"commit":0,"type":"research"},"fileAbsolutePath":"/Users/husky/huskydoge.github.io/example/content/research/2025/pan/index.md","fields":{"slug":{"html":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"PAN: Towards General World Model with Natural Language Actions and Video States\",\n  \"tags\": [\"World Model\", \"Image to Video\", \"Diffusion\"],\n  \"authors\": [{\n    \"name\": \"**Benhao Huang**\"\n  }, {\n    \"name\": \"Pandora Team\"\n  }, {\n    \"name\": \"Zhiting Hu\",\n    \"url\": \"https://zhiting.ucsd.edu/\"\n  }, {\n    \"name\": \"Eric P. Xing\",\n    \"url\": \"https://www.cs.cmu.edu/~epxing/\"\n  }],\n  \"path\": \"research/2025/pan\",\n  \"excerpt\": \"A step towards a General World Model (GWM) that can simulate complex video scenarios with natural language actions.\",\n  \"selected\": true,\n  \"cover\": \"./preview.png\",\n  \"links\": [{\n    \"name\": \"paper (in progress)\"\n  }, {\n    \"name\": \"report-v1\",\n    \"url\": \"https://world-model.maitrix.org/assets/pandora.pdf\"\n  }, {\n    \"name\": \"code\",\n    \"url\": \"https://github.com/maitrix-org/Pandora\"\n  }],\n  \"priority\": 0\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Diffusion Game Engine:\"), \" Built an auto-regressive Image-to-Video (I2V) model capable of simulating 2D platformer games (e.g., Mario), allowing control of both characters and environmental elements using text inputs on the fly. Proposed and implemented window-slide conditioning to support the generation of game videos lasting longer than one minute.\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Video Diffusion Model Acceleration:\"), \" Spearheaded a sub-project focusing on optimizing video diffusion for real-time game generation, achieving generation speeds of under 1 second per round.\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Complex Video Captioning:\"), \" Led a sub-project aimed at enhancing video captioning for complex scenarios (e.g. game videos) where even state-of-the-art visual language models tend to falter, ensuring more accurate descriptions.\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Large-Scale Training Data Pipeline:\"), \" Designed and implemented a high-efficiency processing pipeline for video training data, processing over 10 million videos simultaneously, significantly improving the overall data quality and processing speed.\"))), mdx(\"p\", null, mdx(\"img\", {\n    parentName: \"p\",\n    \"src\": \"/files/a650c4eabaded37a600596a459457f7b/mcts.png\",\n    \"alt\": \"mcts\"\n  })), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"text\"\n  }, mdx(\"pre\", {\n    parentName: \"div\",\n    \"className\": \"language-text\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }))));\n}\n;\nMDXContent.isMDXComponent = true;","htmlEncrypted":"","nonce":""}}}},"pageContext":{"fileAbsolutePath":"/Users/husky/huskydoge.github.io/example/content/research/2025/pan/index.md","postPath":"research/2025/pan","translations":[{"hreflang":"en","path":"/research/2025/pan"}]}},
    "staticQueryHashes": ["1552981879","2213578703","4097791827"]}