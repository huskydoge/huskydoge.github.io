{
    "componentChunkName": "component---gatsby-theme-academic-src-templates-post-post-jsx",
    "path": "/research/2025/wm-bench",
    "result": {"data":{"mdx":{"timeToRead":1,"tableOfContents":{},"frontmatter":{"cover":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='400'%20height='302'%20viewBox='0%200%20400%20302'%20preserveAspectRatio='none'%3e%3cpath%20d='M320%2025l-2%204v2l2-1%205-1h4l-2%202c-3%202-10%203-10%201h-1c-2%200-2%202-2%206s-1%206-2%207v2c2-1%202%200%202%201l1%202%201-2-1-2v-1l5-1%208-2%205-2%203-1-2-1-2-2-1-3-1%203-2%205c-2%201-2%201-2-3%200-5%202-8%205-7l1-1c0-2-1-2-5-2-6%200-6%200-6-3-1-2-1-2-1%200m44%2025c-3%201-3%202%201%201%202%200%202%200%201%202-2%202-2%204%200%207%201%202%201%203-2%201l-3-1c-1%201%206%204%209%204s10-3%209-4l-3%201c-3%202-3%201-1-2v-5c-3-4-1-4%204%200%203%202%203%202%201%204v2l2-2c5-5-10-11-18-8M244%2066c-2%201-2%202-2%204s0%204-2%205c-3%204-2%205%202%206%205%200%203%202-2%202l-5%201-2%203c-4%203-2%209%203%209s6-5%203-8c-4-4-3-4%207-4s11%200%207%204c-2%202-3%204%200%206%202%202%206%202%207%200%202-2%200-7-2-7l-1-2c0-2-1-2-5-2l-5-1%205-1c7%201%2010-2%208-7-1-2-8-3-8-1l-1%201-1-4c0-4-3-6-6-4m78%203c1%202-2%204-3%202s-3%200-2%202c0%201%200%202-2%202-1%201-1%201%201%201l3-1c3-4%209-2%2012%203%201%203%201%203-1%206l-3%203-3%201h-1l-1-1h-3l-2-1c-1%200-2%200-1%201l-1%201-2%201c0%202%2015%201%2018-1s5-7%203-11l-1-4c2-2%200-4-2-2-2%201-4%200-4-2l-2-2c-3%200-3%200-3%202m45%2021l-3%205-1%202-1-4-1-5-1%204-1%205v3l2%203%201-3%202-3%203%203%205%203c2%200%206-3%204-3v-2c0-3%202-4%202-1h1c3-2-3-10-7-10l-5%203m-122%2056l-1%2043c-1%201%201%206%202%206s3-5%202-6l-1-42-1-42c-1-1-1%2013-1%2041m84-35c-2%202-2%206%200%208%201%202%206%202%207%200%204-3%201-10-3-10l-4%202m-204%2016l5%2014c1%201%203-1%204-5l2-2%202%204c2%205%204%203%207-4%202-6%202-8%200-8l-3%205-2%204-1-4c-2-6-4-6-6%200-2%205-2%205-4-1-1-4-4-6-4-3m23%200c-1%204%200%2013%202%2014%202%200%202-1%202-4v-3l2%202c0%202%202%203%202%203l3-3%201-2%201%203c0%203%201%204%202%204l1-7c-1-9-2-10-5-4l-3%204-2-4c-3-4-5-5-6-3m18%209l2%201%202%201-12%2015-6%206-2-2c-5-4-8-1-8%205%200%204%200%204-4%207-5%203-12%203-13%200v-3c2-1%202-2%201-3v-5c1-2%202-2%202%203l1%205h5c5%200%208-2%206-6v-3c2-3-2-6-6-6-5%200-5%200-7%204l-3%204-2-4-3-4c-1%200-7%2011-7%2014%200%202%203%201%203-1l4-1c3%200%204%201%204%204%200%207%207%208%2017%202l8-3c5-1%205-3%200-3h-3l4-1c3%200%204%200%204%202%201%204%203%203%204-1%201-5%202-5%203-1%201%206%204%205%204%200%200-4%200-5-3-6l-2-1%203-3%2011-17c-1-2-7-1-7%201m-134%200c-14%206-16%2025-3%2033%2012%208%2028-1%2028-15s-14-23-25-18m9%204v3l1%202c1%202%201%205-1%205-1%200-2%201-1%202%200%202%200%202-3%202-1%200-7%206-6%207l3%201h4c2-2%205-2%205%200l-1%201c-1-1-2%200-3%201h-4c-2%200-2%200-1%201l1%203c0%203%207%203%2012%200%204-1%203-5-1-4l-2-1c0-2%204-2%206%200s2%202%203-1c2-4%202-6%200-8l-1-2c1-1%203%200%203%202%201%201%201%201%201-1%200-4-3-10-7-13s-5-3-2%200c2%202%202%203%201%206%200%202%200%203%202%205v1c-3%200-4-3-4-6%201-3%200-4-1-6-4-4-5-4-4%200m-16%209l2%209v3l3-3%203-4%203-1c2%200%202%200%201-2-1-1-2-2-1-3%200-2%200-2-3-2l-6-2-2-1v6m322%2035l-2%202-2%201c0%202-2%204-5%204l-1%202-2%202c-2%201-3%204%200%204v2c-1%202%200%204%202%204l1%201c0%201%202%202%205%202%204%200%205%200%205-2l2-2%202-1c0-4%201-6%203-6%201-1%202-1%201-3l1-2v-2l-2-3c0-2-1-2-2-2-1%201-2%200-2-1h-4m-4%207c-1%202-2%202-3%202-2-1-3-1-2%201l-1%203c-2%200-2%201-1%202l1%202c-1%201%200%202%201%202l2%202%201%201%202-1%202%201%201-1%203-2c1%200%202%200%201-1-2%200-1-3%201-4l-1-1-2-2-1-2-3-2h-1m-241%2032v3l-2%201c-3%200-8%205-8%208s3%203%204%200l2-2c1%201-3%2010-6%2014-2%202-3%204-2%205%201%202%204%201%207-4l5-4%202%201-1%203c-1%204%201%206%204%204l1-4c0-2%200-2%202%201%202%205%209%205%2011%200l1-4-1-2-2-2-2-1c-1-1-7%202-7%204l-1-1-3-3c-4-1-2-2%203-2%206%201%208-2%202-3-4%200-7-6-4-8%202-2%202-2%201-4-1-3-5-3-6%200m133%203c-1%202%201%202%2010%202h9v2c0%203-5%204-8%201h-4l-5%202-4%202-2%204c-3%204%203%207%206%204%202-3%2013-3%2015%200%202%202%202%204-1%204-1-1-2%200-2%205v6l4-1h5c3%200%203-10%200-10-2%200-2-2-1-4l1-3c-1-3-4-4-6-2-3%204-17%202-17-2%200-2%206-1%207%201h4l6-2c3%200%204-1%204-4v-4l-10-1h-11m-96%202l-3%203c0%202%200%202%201%201%200-2%200-2%203%200h4c0-2%205-2%2034-2l35-1h-35l-34-1c0-2-1-2-5%200m196-1l-1%202v2c-2%203-4%2012-3%2013%201%202%202%201%203-2%200-2%200-2%201%200%201%204%203%202%203-3l1-5c2%200%202%200%202%203l-2%205c0%202%203%203%204%202l2-7%202-5v6c0%205%201%207%202%207%202%200%202-1%202-8v-9h-4l-4%201c0%201-1%202-3%202l-2-2c1-2-2-3-3-2m-104%2020c-4%201-4%2010-1%2010h5l4%201v-6c-1-6-2-7-8-5m101%2013v8l1-1%201-1%203-2c1-1%201-1%203%201h6c0%202%204%201%204-1%201-1%200-1-1-2l-2-1%202-1h1l-2-1c-3%200-3%204%200%204%201%201%201%201-1%201l-2-2c-1-3-4-4-6-2-1%202-1%202-2%201%200-2-4-3-5-1m10%208l-3%202h2c4-1%206-1%2010%201l4%202-4%202-5%202-6-2c-4-2-5-3-3-3%201-1%201-1-1-1-3%200-4%202-1%203v2c-2%201-3%203%200%203%201%200%201%201-1%203-1%201-1%201%204%203%207%204%207%204%2014%200%206-2%207-4%203-4v1l-4%203-6%202-5-2c-5-2-5-3-3-3h5c4%202%206%202%206%200h-1c-3%201-13-4-11-5h18c2%200%202%200%201-1s-1-1%201-2c3-1%202-2-4-4-7-3-6-3-10-2'%20fill='%23d3d3d3'%20fill-rule='evenodd'/%3e%3c/svg%3e","aspectRatio":1.3227513227513228,"src":"/static/6ff9fe434382942e85ce0e87a3a4ed21/31987/preview.png","srcSet":"/static/6ff9fe434382942e85ce0e87a3a4ed21/e1953/preview.png 250w,\n/static/6ff9fe434382942e85ce0e87a3a4ed21/46604/preview.png 500w,\n/static/6ff9fe434382942e85ce0e87a3a4ed21/31987/preview.png 1000w,\n/static/6ff9fe434382942e85ce0e87a3a4ed21/0dadc/preview.png 1500w,\n/static/6ff9fe434382942e85ce0e87a3a4ed21/5c082/preview.png 1584w","sizes":"(max-width: 1000px) 100vw, 1000px"}}},"title":"Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation","date":"2025-06-01","tags":["World Model","Benchmark"],"path":"research/2025/wm-bench","excerpt":"This paper evaluates whether modern Vision-Language Models (VLMs) like GPT-4o and Gemini can act as internal world models (WMs)—systems that understand and predict the world.","links":[{"name":"paper","url":"https://arxiv.org/abs/2506.21876"}],"commit":0,"type":"research"},"fileAbsolutePath":"/home/runner/work/huskydoge.github.io/huskydoge.github.io/example/content/research/2025/wm-bench/index.md","fields":{"slug":{"html":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation\",\n  \"date\": \"2025-06-01\",\n  \"tags\": [\"World Model\", \"Benchmark\"],\n  \"venue\": \"ICLR 2025 Workshop World Models / ACL 2025 Findings\",\n  \"authors\": [{\n    \"name\": \"Qiyue Gao\"\n  }, {\n    \"name\": \"Xinyu Pi\"\n  }, {\n    \"name\": \"Kevin Liu\"\n  }, {\n    \"name\": \"Junrong Chen\"\n  }, {\n    \"name\": \"Ruolan Yang\"\n  }, {\n    \"name\": \"Xinqi Huang\"\n  }, {\n    \"name\": \"Xinyu Fang\"\n  }, {\n    \"name\": \"Lu Sun\"\n  }, {\n    \"name\": \"Gautham Kishore\"\n  }, {\n    \"name\": \"Bo Ai\"\n  }, {\n    \"name\": \"Stone Tao\"\n  }, {\n    \"name\": \"Mengyang Liu\"\n  }, {\n    \"name\": \"Jiaxi Yang\"\n  }, {\n    \"name\": \"Chao-Jung Lai\"\n  }, {\n    \"name\": \"Chuanyang Jin\"\n  }, {\n    \"name\": \"Jiannan Xiang\"\n  }, {\n    \"name\": \"*Benhao Huang*\"\n  }, {\n    \"name\": \"Zeming Chen\"\n  }, {\n    \"name\": \"David Danks\"\n  }, {\n    \"name\": \"Hao Su\"\n  }],\n  \"path\": \"research/2025/wm-bench\",\n  \"excerpt\": \"This paper evaluates whether modern Vision-Language Models (VLMs) like GPT-4o and Gemini can act as internal world models (WMs)—systems that understand and predict the world.\",\n  \"selected\": false,\n  \"cover\": \"./preview.png\",\n  \"links\": [{\n    \"name\": \"paper\",\n    \"url\": \"https://arxiv.org/abs/2506.21876\"\n  }],\n  \"priority\": 2\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"This paper evaluates whether modern Vision-Language Models (VLMs) like GPT-4o and Gemini can act as internal world models (WMs)\\u2014systems that understand and predict the world. The authors introduce WM-ABench, a benchmark assessing core perception and prediction abilities (e.g., motion, spatial reasoning, causal inference) across 23 dimensions and 6 simulated environments. Results from 517 experiments show major limitations: VLMs often perform at chance level in motion tasks and exhibit entangled, biased reasoning (e.g., associating object color with speed). The study reveals that current VLMs fall far short of human-like world modeling.\"));\n}\n;\nMDXContent.isMDXComponent = true;","htmlEncrypted":"","nonce":""}}}},"pageContext":{"fileAbsolutePath":"/home/runner/work/huskydoge.github.io/huskydoge.github.io/example/content/research/2025/wm-bench/index.md","postPath":"research/2025/wm-bench","translations":[{"hreflang":"en","path":"/research/2025/wm-bench"}]}},
    "staticQueryHashes": ["1552981879","1858131618","4097791827"]}